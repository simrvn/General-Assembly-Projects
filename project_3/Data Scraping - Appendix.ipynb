{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b396aa",
   "metadata": {},
   "source": [
    "# Data Scraping - Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ff8573",
   "metadata": {},
   "source": [
    "Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd01869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55676a6f",
   "metadata": {},
   "source": [
    "##### Subreddit 1: r/datascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4891be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of the subreddit we want to extract our posts from\n",
    "url = 'https://www.reddit.com/r/datascience.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce6575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df to store posts from json\n",
    "df = pd.DataFrame(columns=['title'])\n",
    "#export df as a csv file\n",
    "df.to_csv('./data/datascience.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff2b666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/datascience.json\n",
      "2\n",
      "https://www.reddit.com/r/datascience.json?after=t3_o3d3jm\n",
      "3\n",
      "https://www.reddit.com/r/datascience.json?after=t3_o2q9o8\n",
      "5\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nzhzxq\n",
      "6\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nxi5db\n",
      "5\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nwfvo3\n",
      "5\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nvn42p\n",
      "3\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nu52fh\n",
      "2\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nsojd5\n",
      "2\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nrhzbw\n",
      "2\n",
      "https://www.reddit.com/r/datascience.json?after=t3_npuamu\n",
      "2\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nn4j8q\n",
      "5\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nlql25\n",
      "5\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nk5dny\n",
      "4\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nhi11p\n",
      "6\n",
      "https://www.reddit.com/r/datascience.json?after=t3_ng287u\n",
      "2\n",
      "https://www.reddit.com/r/datascience.json?after=t3_ndt83g\n",
      "2\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nbk99e\n",
      "3\n",
      "https://www.reddit.com/r/datascience.json?after=t3_n959rr\n",
      "4\n",
      "https://www.reddit.com/r/datascience.json?after=t3_n6c4vh\n",
      "4\n",
      "https://www.reddit.com/r/datascience.json?after=t3_n3n4hb\n",
      "6\n",
      "https://www.reddit.com/r/datascience.json?after=t3_n0oz21\n",
      "5\n",
      "https://www.reddit.com/r/datascience.json?after=t3_mwxyac\n",
      "4\n",
      "https://www.reddit.com/r/datascience.json?after=t3_mtanu3\n",
      "3\n",
      "https://www.reddit.com/r/datascience.json\n",
      "6\n",
      "https://www.reddit.com/r/datascience.json?after=t3_o3d3jm\n",
      "2\n",
      "https://www.reddit.com/r/datascience.json?after=t3_o2q9o8\n",
      "2\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nzhzxq\n",
      "5\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nxi5db\n",
      "5\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nwfvo3\n",
      "5\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nvn42p\n",
      "2\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nu52fh\n",
      "6\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nsojd5\n",
      "3\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nrhzbw\n",
      "4\n",
      "https://www.reddit.com/r/datascience.json?after=t3_npuamu\n",
      "6\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nn4j8q\n",
      "3\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nlql25\n",
      "4\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nk5dny\n",
      "4\n",
      "https://www.reddit.com/r/datascience.json?after=t3_nhi11p\n",
      "6\n",
      "https://www.reddit.com/r/datascience.json?after=t3_ng287u\n",
      "3\n",
      "https://www.reddit.com/r/datascience.json?after=t3_ndt83g\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "posts = [] #list of all posts\n",
    "after = None\n",
    "\n",
    "#while loop where title is not null to ensure that there are 1000 posts extracted\n",
    "while df['title'].notnull().sum() < 1000:\n",
    "    if after == None:\n",
    "        current_url = url\n",
    "    else:\n",
    "        current_url = url + '?after=' + after\n",
    "    \n",
    "    print(current_url) #print current url\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Lucifer Morningstar 20.0'})\n",
    "    \n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "    \n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    #store posts as dataframe to save as csv thereafter\n",
    "    pd.DataFrame(posts).to_csv('./data/datascience.csv', index = False)\n",
    "    df = pd.read_csv('./data/datascience.csv')\n",
    "        \n",
    "\n",
    "    #random sleep duration to look more natural\n",
    "    sleep_duration = random.randint(2,6)\n",
    "    print(sleep_duration)\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e9d5a",
   "metadata": {},
   "source": [
    "##### Subreddit 2: r/SoftwareEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e851591",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.reddit.com/r/SoftwareEngineering.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16e9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['title'])\n",
    "\n",
    "df.to_csv('./data/softwareengin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc10a88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/SoftwareEngineering.json\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_nsao4d\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_njy8ba\n",
      "2\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_ncy7be\n",
      "4\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_n2xqe7\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_mu2961\n",
      "6\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_mm4bd2\n",
      "4\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_mh3chw\n",
      "3\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_m94ct2\n",
      "3\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_m6b15e\n",
      "4\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_lxjme7\n",
      "3\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_lorx8g\n",
      "2\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_ljs60e\n",
      "4\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_lfwaov\n",
      "4\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_lat7h4\n",
      "3\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_l4t5xj\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_l0awbm\n",
      "3\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_kvxrtw\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_kokie1\n",
      "4\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_kiuwu9\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_kdxtgi\n",
      "4\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_k962nw\n",
      "3\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_k3l9em\n",
      "4\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_jzii9s\n",
      "2\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_jvy91j\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_jsdol4\n",
      "4\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_jo7syg\n",
      "2\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_jlpezy\n",
      "2\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_jj0qes\n",
      "6\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_jesxxv\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_j9hvf8\n",
      "3\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_j56uvg\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_j00axh\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json\n",
      "6\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_nsao4d\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_njy8ba\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_ncy7be\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_n2xqe7\n",
      "2\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_mu2961\n",
      "3\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_mm4bd2\n",
      "5\n",
      "https://www.reddit.com/r/SoftwareEngineering.json?after=t3_mh3chw\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "posts = [] #list of all posts\n",
    "after = None\n",
    "\n",
    "#while loop where title is not null to ensure that there are 1000 posts extracted\n",
    "while df['title'].notnull().sum() < 1000:\n",
    "    if after == None:\n",
    "        current_url = url\n",
    "    else:\n",
    "        current_url = url + '?after=' + after\n",
    "    \n",
    "    print(current_url) #print current url\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Lucifer Morningstar 25.0'})\n",
    "    \n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "    \n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    #store posts as dataframe to save as csv thereafter\n",
    "    pd.DataFrame(posts).to_csv('./data/softwareengin.csv', index = False)\n",
    "    df = pd.read_csv('./data/softwareengin.csv')\n",
    "        \n",
    "\n",
    "    #random sleep duration to look more natural\n",
    "    sleep_duration = random.randint(2,6)\n",
    "    print(sleep_duration)\n",
    "    time.sleep(sleep_duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
